%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Efficient Optical Flow for Faces}\label{sec:face_flow_intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Computing optical flow in the presence of non-rigid deformations
is an important and challenging task. It plays a significant role in a wide variety of 
problems such as medical imaging, dense non-rigid 3D reconstruction, 
dense 3D mesh registration, motion segmentation, video re-texturing and super-resolution.
Broadly, optical flow methods describe procedures to relate pixels in
one image to pixels in another image of the same object. They establish a 
displacement field that can be thought of as a sampling, or warping, of the input 
image back onto the reference image. Traditionally, optical flow is applied on a pair 
of consecutive frames of a sequence, treating one of the frames as the template.
However, in terms of revealing the dynamics of a non-rigid scene, it is much more 
useful to estimate the optical flow between every frame of a long sequence and a 
common template. In this scenario, long-term dense 2D tracks across the sequence
are established. We tackle the problem of multi-frame optical flow by focusing on a 
specific deformable object, the human face.

The most straight-forward way to estimate a multi-frame optical flow is to apply an 
algorithm that solves the traditional two-frame optical flow problem between every 
frame and the template independently.
However, the fact that we wish to deal with long sequences poses major difficulties. 
For example, the point displacements between the template and a frame can be substantially 
large and severe occlusions of parts of the template can occur in some frames. Even 
state-of-the-art two-frame optical flow methods that are especially designed to deal 
with large displacements or occlusions, \eg~\cite{brox2011large,revaud2015epicflow}, 
are  prone to fail. This is because they lack any additional cues that could help
them estimate an appropriate initialisation or to disambiguate severe occlusions.

An alternative solution to the multi-frame optical flow problem, also based on 
two-frame optical flow, is to estimate flow between consecutive frames and then 
combine the various solutions. A simple integration of the solutions to obtain long-term 
2D tracks is prone to drift due to error accumulation~\cite{cosker2011facs,brox2011large}.
This can be improved by the automatic detection of occlusions, gross errors, 
and other ambiguities~\cite{sand2008particle,sundaram2010dense,%
rubinstein2012towards,ricco2012simultaneous,papamakarios2011generalised}, 
but any such solution is still limited by the accuracy of the initial two-frame
optical  flow estimations that are completely local in time and do not exploit
any temporal cues.

Several recent methods solve the multi-frame optical flow problem directly, by 
implicitly taking into account the rich temporal information that is present in 
non-rigid scenes~\cite{irani2002multi,torresani2001tracking,torresani2002space,%
tomasi2012dense,ricco2013video,garg2013variational}. 
For example, the long-term 2D trajectories of points on a surface undergoing
non-rigid deformation are highly correlated and can be compactly described
via a linear combination of a low-rank trajectory basis. 
This basis is typically learnt from the input sequence itself. In 
this way, these methods are more robust to occlusions and yield a temporally coherent 
result. However, they rely only on some generic spatial and temporal regularisation 
priors, applicable to any deformable object and do not utilise any prior knowledge 
about the specific object observed in the scene. This makes them fail in more challenging 
conditions that often occur in real-world scenes, such as severe occlusions or 
significant illumination changes, which cannot be disambiguated by temporal
regularisation alone.
Furthermore, the memory and runtime efficiency of all existing multi-frame optical 
flow methods is limited by the fact that they have to estimate a very large number 
of parameters, \ie~a set of parameters for every pixel of the template.
Specially designed parallelisable algorithms, such as primal-dual optimisation
schemes~\cite{wedel2009improved,garg2013variational} 
can be adopted. However, even with the recent advances in GPU hardware these
methods are very costly to apply.

In this chapter, we overcome the aforementioned limitations by incorporating a face-specific 
deformation model into the multi-frame optical flow estimation. We assume a learnt 
deformation basis, rather than one calculated directly from the sequence itself. We 
focus on human faces which are a very commonly considered object in computer vision, 
and dense face correspondences are required in many research areas and applications. 
That is, the establishment of dense correspondences of deformable faces is the first step 
towards high-performance facial expression recognition~\cite{koelstra2010dynamic},
facial motion capture~\cite{Beeler:2011ey} and 3D face reconstruction~\cite{garg2013dense}. 
Nevertheless, computing dense face correspondences has received limited attention 
\cite{decarlo2000optical,yacoob1996recognizing}. This is attributed to the difficulty of 
developing a statistical model for dense facial flow due to the in-ability of humans to 
densely annotate sequences and the limited robustness of the optical flow techniques 
\cite{decarlo2000optical}. Hence, the research community has focused on developing 
statistical facial models built on a sparse set of landmarks~\cite{xiong2013supervised}, 
which provide limited accuracy to the recognition of subtle expressions~\cite{li2013spontaneous}. 
In this work, we build two statistical models of dense facial flow. In the first,
we capitalise on the success of recent optical flow techniques applied to
densely tracking image sequences~\cite{garg2013variational} by building a
statistical model from the output of~\cite{garg2013variational}. The second
model construction method is to use a 3D statistical model and render it in
order to learn a statistical model of the 2D projections.

Due to the use of a statistical low-rank model, and in contrast to existing 
approaches, our method is able to deal with 
particularly challenging conditions such as severe occlusions of the face and strong 
illumination changes. Furthermore, we exploit the even higher correlation 
between face deformations in 
a specific input sequence by imposing a low-rank prior on the coefficients of the 
deformation basis. This acts as a data-specific regularisation term leading to 
temporally consistent optical flow.
We also incorporate a sparse landmark prior term to guide the flow estimation in
sparse point locations that are accurately predicted by state-of-the-art face 
alignment methods~\cite{kazemi2014one}.
We formulate the photometric cost by utilising a state-of-the-art dense 
feature descriptor that offers robustness even with the usage of a simple
quadratic penaliser.
Our proposed model-based problem formulation, in conjunction with the inverse 
compositional strategy~\cite{baker2004lucas} and low-rank matrix optimisation
that we adopt, leads to a highly efficient algorithm for calculating optical
flow across a facial sequence.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Further Related Work}\label{subsec:face_flow_further_related_work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
There is a very large body of work on facial alignment that largely revolves
around the concept of identifying a set of sparse target landmarks within an
image. The most relevant algorithm to our proposed method is that of the
Active Appearance Model (AAM)~\cite{cootes2001active}, particularly the
variation by \citet{matthews2004active} that relates AAMs to the 
Lucas-Kanade~\cite{lucas1981iterative,baker2004lucas} optical flow literature. 
However, our method does not incorporate an appearance model and relies on a 
single given template image and is thus closer in nature to the original 
Lucas-Kanade algorithm. 
Our algorithm also places a low-rank constraint on the shape model coefficients
enforcing a form of temporal consistency, which has not been previously 
considered.

It is also important to note that, other than a couple of examples
\cite{ramnath2008increasing,anderson2014using}, the AAM literature has focused
on the recovery of sparse landmarks, not a dense motion field as in this work.
Even in the cases of \citet{ramnath2008increasing,anderson2014using}, 
the warping of the input images is achieved via an interpolation method such as
piecewise affine or thin-plate splines. In this work, our warping
method is derived directly from the deformation basis itself and thus recovers
dense correspondences.
As we show in Section~\ref{sec:face_flow_method}, the linear nature of our warp
allows us to derive a very efficient optimisation strategy,
based on the Inverse Compositional algorithm proposed by Baker and Matthews
\cite{baker2004lucas}. 

Finally, the work of \citet{kemelmacher2012collection}
is relevant as it considers learning deformation fields between images of faces.
However, \citet{kemelmacher2012collection} considers an optical flow method
as a key component of the method and does not propose a novel optical
formulation, in contrast to our proposed model-based algorithm.
