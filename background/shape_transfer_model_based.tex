%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Model-based and Alignment Methods}\label{sec:bg_model_based}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this section we considered methods that seek to recover 3D by the use
of explicit models of faces. Given some model of the 3D structure of a human
face, it is possible to attempt to find some feature of the input image
that is best matched to some aspect of the model. We separate the literature
into two distinct areas: those that consider reconstruction as a problem of
alignment and those that seek to recover structure from the model assuming
alignment is solved. In contrast to other seemingly similar techniques such as
3D Morphable Models~\cite{volker1999morphable} that use 3D statistical models
of faces the methods considered in this section do not necessarily enforce any
specific structure on the formation of the image.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Model-based Methods}\label{subsec:bg_model_based_model}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%TODO: Check Castelan's work
\citet{minsik2013robust} propose a direct mapping from 3D facial shape to an
image of a face under general unknown lighting. The depth and texture pairs from
FRGC~\cite{phillips2005overview} are used to generate a discrete set of
renderings of faces with cast shadows. N-Mode
SVD~\cite{vasilescu2003multilinear} followed by orthogonalisation is applied to
both the rendered textures and the depths in order to perform dimensionality
reduction. This provides a set of transformed images and a subspace is recovered
using a generalised eigenvalue method to further reduce the dimensionality.
Finally, Canonical Correlations Analysis (CCA) is applied between the
dimensionality reduced depth images and a hyperspherical representation of the
image subspace. At test time, the image is transformed using the subspace and
the depth is recovered using the CCA mapping. This process is very fast for
recovery of an input image and handles arbitrary lighting conditions, but
only applies to frontal faces and does not guarantee photometric consistency
of the recovered shape.
\citet{minsik2014realtime} extend the work of \citet{minsik2011fast} with a
novel optimisation procedure that is extremely efficient. Similar
to~\cite{minsik2011fast}, a tensor formulation is proposed. However, the
bilinear model of~\cite{minsik2011fast} is relaxed by enforcing that the
illumination and identity modes can be described as a set of rank-one matrices.
Furthermore, in order to incorporate cast shadows, they render the input meshes
under a variety of illumination conditions including cast shadows and perform
the tensor decomposition on the rendered data rather than the spherical
harmonics, similar to \citet{minsik2013robust}. At test time, the input image
is projected against the bilinear illumination basis and the best rank-one
structure of the lighting and identity coefficients are recovered. The images
are aligned using affine alignment of the eye centres and depth is recovered
from the learnt tensor depth model and the recovered rank-one identity
coefficients.

%TODO: Check with stefanos that the solution to this is linear
\citet{castelan2007coupled} take inspiration from the original coupled 
texture and shape model of 2D AAMs~\cite{cootes2001active} and couple image
intensity and surface height representations. They investigate three surface
height representations including the surface derivatives, the surface height
and a fourier basis of the surface derivatives. The coupled model is created
by constructing PCA models for both intensity and shape inputs and then
further constructing a joint PCA on the coefficients of the intensity and shape
PCA models. At test time, the best fit coefficients for the joint model are
constructed by minimising the difference between the coefficients of
the input image, found by projecting the input iamge against the intensity PCA
basis, and the best reconstruction from the joint model. This is a simple
least squares problem that assumes that the input image is aligned
with the intensity PCA basis. \citet{ahmed2007new} extend this work to
include a spherical harmonic basis to represent shape. This enables
the recovery of the albedo and thus illumination conditions are also
recovered. Similarly, \citet{rara2009model} minimise the error between
an intensity and shape model using spherical harmonic basis, but solve for 
each mode seperately. They describe this as following a ``project-out'' 
method~\cite{matthews2004active} and first solve for the shape, fixing the 
intensity and then solving for the intensity with the recovered shape. 
\citet{rara2010face} also employ a spherical harmonic basis but use
Partial Least Squares (PLS) to recovery the best shape parameters.

\citet{rara2011model} use principal component regression in order to map
a set of known 2D landmarks to the parameters of a statistical 3D shape model.

\citet{kouzani1998example} build a texture space model by rendering a set of
textured 3D meshes into fixed poses. Each of the pose clusters is futher aligned
via an image warping and a PCA subspace is constructed per cluster. A test image
is aligned via optical flow to the mean of the correct pose cluster and the PCA
coefficients are obtained. The key assumption is that the PCA of texture and PCA
of 3D shape can share the same coefficients despite being differing subspaces.
Thus, the coefficients from the texture PCA basis are used to reconstruct the 3D
shape using the manually aligned 3D shape PCA basis.

\citet{Yang:2011gj} require accurate dense 3D shape estimation in order to
perform expression transfer between images. Given a set of known 2D landmarks on
the input image a dense 3D bilinear statistical model is deformed so as to
minimise the re-projection error. Landmarks on the occluding contour are
optimised separately in order to ensure correct 2D-3D correspondences. This
fitting is performed jointly for the two input images in order to attempt to
ensure consistency of identity.
Similarly, \citet{yang2012face} perform 3D expression transfer
but augment the initial 3D shape estimation with a restricted camera model
rather than a weak perspective model.

\citet{Garrido:2013dia} used the 2D facial landmarking method of
\citet{saragih2011deformable} to track a set of sparse feature points across
a sequence. Key frames are detected as frames where the 2D landmarking was
deemed accurate, according to the difference between the frame and a neutral
frame. Optical flow is used to correct the 2D landmarks and pose and blend shape
optimisation are iterated to perform 3D tracking. Finally, the tracked
blend shape is deformed by the optical flow estimates and a Shape-from-Shading
refinement method~\cite{valgaerts2012lightweight} is used to include finer
surface detail such as wrinkles.

\citet{ferrari2015dictionary} used the method of
\citet{xiong2013supervised} to provide sparse 2D landmarks and perform
an alternating ridge regression to solve for pose and the parameters of a sparse
dictionary of dense 3D faces.
%TODO: Shape-from-silhoette and shape-from-contours both fall in this section
%      due to the fact that all the methods I can find use models!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Alignment Methods}\label{subsec:bg_model_based_alignment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%TODO: Roughly this section is split like: 3D head tracking, 
%      augmenting 2D with 3D, direct 3D regression, possibly expression
%      transfer - though that may be model based
Alignment based 3D recovery methods attempt to recover the best possible
reconstruction of an input model for an input image. Unlike purely model
driven methods, alignment algorithms assume that the initialisation will not be
perfect and thus attempt to deform the model in some manner in order to best
replicate some feature of the input image. Unlike 3DMMs, alignment methods
do not necessarily try to synthesize the image, but instead focus on learning
relationships between some feature of the image and the model.

\cite{terzopoulos1993analysis} build a physics based synthetic tissue model
for a sparse generic 3D model coupled with a set of anatomically motivated
muscle activators. Contours are extracted from input images and the physically
based model is used to deform the generic mesh. Similarly,
\citet{essa1997coding} use a low vertex generic face mesh and augment it with
an anatomically based muscles model. This model uses the Facial Action Coding
System (FACS)~\cite{ekman1977facial} to parametrise face motion. Landmarks
are used to initialise the face model onto a frontal face and then optical
flow is performed. The displacements recovered by optical flow from a
neutral pose are then fed into an optimisation that deforms the mesh according
to the physically based muscle model.
\citet{jebara1997parametrized} track the 3D motion of a face using a generic
dense 3D face mesh and a modified rigid Structure-from-Motion algorithm
to recover the head pose. Symmetric frontalisation is performed on the face
within the image and an Extended Kalman Filter (EKF) is used to perform motion
updates that are consistent for the 3D model. The EKF is filtered by an
eigenspace of frontalised 3D faces to constraint the tracking to plausible face
shapes.
\citet{basu1996motion} regularise optical flow with an ellipsoidal mesh
to approximate a facial shape, which they show to be superior to planar
tracking.
\citet{lacascia1998head,la2000fast} do not concentrate on 3D reconstruction but
perform 3D head tracking by approximating the head shape as a cylinder and
performing alignment in the texture mapped space. In \citet{la2000fast} this
is extended with a statistical model of illumination variance built from
many aligned images of various individuals under differing illumination.
\cite{schoedl1998head} used a more realistic textured model than
\citet{lacascia1998head} and employ a low vertex count 3D generic face model. A
single frontal texture is extracted and used in an ``analysis-by-synthesis''
manner to minimise the difference between the input image and the rendered
model.
\citet{decarlo2000optical} employ a sparse generic model that is parametrically
deformed by a set of static shape parameters and motion deformation
parameters. The model is initialised by hand on a neutral frontal image and
optical flow is then employed for tracking. The parameters of the
3D deformable motion model are hard constrained by the result of the flow.
To combat tracking drift, image edge features are introduced as another
constraint.
\cite{decarlo2002adjusting} extends the work of \citet{decarlo2000optical} with
an extra regularisation based on minimising the residual error from the
framework of \citet{decarlo2000optical}. Minimising these residuals with respect
to a linearisation of the model parameters results in a more robust recovery of
the facial shape and thus reduces the optical flow residual in a manner
consistent with facial deformations.
\citet{goldenstein2004facial} focus on the estimation of the update for
the deformable model by using multiple image features (optical flow,
edges, feature points) and assume their independence. The independence
of these features enables the use of a multivariate Gaussian approximation
to estimate displacements using a Kalman filter.
\citet{pighin2002modeling} manually specify a set of landmarks and deform
a single dense generic template head to multiple poses images of a subject.
Rigid Structure-from-Motion is used to estimate the head pose, initialised
by the rough estimate of the known pose of the face \eg~side-view, frontal \etc.
All the vertices in the generic mesh are then deformed by landmarks
using a radial basis function including an additional 100 correspondences
that are hand specified and a view-independent texture is created from the input
images. This person specific model is then fit to an input
sequence by using a non-linear least squares algorithm similar to the Active
Appearance Model (AAM) but with a 3D model. The ``analysis-by-synthesis''
objective involves rendering the input mesh but no lighting conditions are
modelled.

\citet{lie2006alignment} propose to model a 3D face as a set of sparse patches
rendering from the 3D model over various poses. An expectation maximisation
method is proposed to predict the parameters of a sparse 3D statistical face
model (deformation) and pose parameters from a given 2D observation. Pose
and deformation are solved for alternately.
\cite{Matthews:2007gb} provide a detailed analysis on the advantages
of imposing 3D priors for Active Appearance Model alignment. They propose to
build the 2D statistical model from samples of a projected 3D model and then
to constrain the 2D fitting by the 3D model. The 3D model is sparse and learnt
via Structure-from-Motion on the training set. \citet{Ramnath:2008jp} extend
\cite{Matthews:2007gb} in order to perform alignment on multiple posed
images of an individual. By leveraging the additional information from
multiple images they show improved fitting performance across all views.
\cite{Martins:2013hp} also propose a 3D AAM, but employ a fully perspective
camera model and show how to optimise via a 3D perspective projection
using a forward additive alignment algorithm. Therefore, no intermediate
2D model is required. Similarly, \citet{saragih2011real} extend their 2D
face alignment work~\cite{saragih2011deformable} on Constrained Local Models
(CLMs)~\cite{cristinacce2006feature} to fit a 3D CLM.\@ These sparsely
tracked points were primarily demonstrated for avatar animation.
\cite{Liao:2010fy} use both raw pixel intensities as well as
SIFT~\cite{lowe2004distinctive} as input to an inverse compositional alignment
algorithm~\cite{baker2004lucas} evaluated for face tracking. The SIFT features
are required to be distant from one another and matched features must be close
between frames.
\citet{Wang:2011kr} propose a one-shot optimization approach to simultaneously
estimate the sparse 3D landmarks, the corresponding 2D projections and their
visibility states without requiring explicit estimation of the camera
parameters. A higher order Markov Random Field (MRF) is used to encode the
outputs and optimised via a dual-decomposition optimisation
framework~\cite{komodakis2007mrf}.

\printauthor{Cao:2013cd} proposed a series of works for efficient blend shape
tracking from a monocular sequence. Using their collected database,
FaceWarehouse~\cite{Cao:2014gy}, \citet{Cao:2013cd} first proposed a person
specific method for 3D face tracking. A person specific regressor was learnt
from a set of acted expressions in order to map 2D facial images to 3D blend
shape parameters. This initial recording specific training was important in
order to learn the cameras intrinsic parameters. In \citet{Cao:2014bi}, the
authors relax the requirement for a person specific calibration process and
propose to learnt the camera intrinsic and subject identity parameters in an
online manner. Using the same 3D regression scheme as in
\citet{Cao:2013cd}, the camera and identity parameters are updated online when
a new representative frame is detected. These frames are detected via distance
from a PCA subspace that is maintained online. Thus the identity and camera
intrinsics are shown to converge over the coarse of an input sequence. Both
\citet{Cao:2013cd} and \citet{Cao:2014bi} use the two-stage cascaded regression
scheme proposed by \citet{cao2014face} to learnt the regression between the
input image and the model parameters. More recently, the work from
\citet{Cao:2014bi} has augmented with a real-time high frequency feature
displacement method by \citet{Cao:2015gy}. Given the coarse geometry recovered
by \citet{Cao:2014bi}, the authors of~\cite{Cao:2015gy} augment the geometry
to include both wrinkles and simple mesoscopic features captured by a narrow
band Difference of Gaussians (DoG) filter~\cite{Beeler:2010dg}. They also
further refine the geometry via GPU Lucas-Kanade~\cite{lucas1981iterative}
optical flow algorithm between each frame. \citet{Chai:2015dq} also
utilised \citet{Cao:2014bi} in order to recover 3D geometry for an input image
to supplement their novel hair synthesis method.

In recent years, cascaded regression methods have become popular for approaching
2D image alignment~\cite{xiong2013supervised,cao2014face,ren2014face,kazemi2014one}.
Given the increased availability to varied 3D face databases, recent works have
directly extended these cascaded alignment methods in order to train 3D cascaded
regression algorithms. \citet{tulyakov2015regressing} train on sparse 3D
landmarks from the BU4D-FE~\cite{yin2008high} and directly extend the method
\citet{kazemi2014one} into 3D. The training set consists of rendered examples
from BU4D-FE.\@ They do not explicitly handle the camera projection and instead
estimate it from the mean shape.
\citet{Jeni:2015ft} propose a semi-dense 2D landmark alignment method that is
learnt from the 3D meshes provided by the BU4D-FE~\cite{yin2008high} and BP4D-
Spontaneous~\cite{Zhang:2014id} databases. At alignment time, only 2D landmarks
are considered and a secondary alternating pose and parameter recovery method is
used to recover 3D shape~\cite{lie2006alignment}. The training set consists of
rendered examples from the database.
\citet{Jourabloo:2015dw} also recover sparse landmarks but they consider a two-
stage regression to regress both the parameters of the 3D shape model and the
camera projection matrix separately. The 3D shape model is learnt from 3D facial
scans and the AFLW~\cite{kostinger2011annotated} database is used to learn the
regressors.
\citet{zhu2015discriminative} use the FRGC~\cite{phillips2005overview} database
to learn both the 3D statistical shape model and the 2D-3D regression. Camera
and shape model parameters are regressed jointly and the method is initialised
by the output of the SDM method~\cite{xiong2013supervised}.
\citet{Huber:2015bs} use a statistical model learnt from the
SURREY~\cite{Huber:F5Dca9zy} database and also jointly regress the camera and
dense shape model parameters. However, no examples of the 3D recovery are given.
All of the aforementioned methods learn to regress from local features extracted
around projections of the 3D model into the image plane. In contrast,
\citet{Zhu:2015ur} use a Convolutional Neural Network (CNN) to learnt a holistic
representation based on all of the input pixels within the original detected
facial bounding box. They also propose to use a set of mesh features from the
current Z-buffered projection of the dense shape estimate and concatenate these
features into a multi-channel image with the texture features. They propose a
novel cost function for jointly optimising the camera and shape model parameters
in a weighted manner. The 3D shape model is bilinear in expression and identity
and is thus built from the FaceWarehouse~\cite{Cao:2014gy} and
Basel~\cite{paysan20093d} databases respectively.
%TODO: Include puppeteering/expression synthesis as its probably most relevant
%      either here or in model-based.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
