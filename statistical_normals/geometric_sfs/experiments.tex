%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments}\label{sec:experiments}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We evaluated the performance of our kernel-base framework for component analysis 
on surface normals within three experimental setups. The experiments performed 
were chosen for two reasons: (1) We wanted to compare the reconstruction 
properties of all KPCA kernels from normals. (2) To compare the statistical 
prior of all KPCA kernels within shape-from-shading. 

We use the BU-4DFE dataset~\cite{yin2008high} and performed manual alignment 
of the scans. We also use FRGC v2 3D face database~\cite{phillips2005overview} to 
provide components of faces when operating within the GSFS framework. In each 
of the experiments, component analysis was performed as described in the 
previous section, and we refer to the AEP kernel as AEP, the PGA kernel as 
PGA, the inner product kernel as IP and the spherical kernel as SPHERICAL\@.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{statistical_normals/images/gsfs_results/sfs-angle}
        \subcaption{The mean angular error per pixel between the ground truth 
                    normals and the reconstructions.}
\label{fig:sfs-angle}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{statistical_normals/images/gsfs_results/sfs-height}
        \subcaption{The mean error per pixel between the integrated shape and 
                    ground truth $z$-values.}
\label{fig:sfs-height}
    \end{subfigure}
    \caption{Quantitative results for shape-from-shading.}
\label{fig:sfs-results-quant}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{statistical_normals/images/gsfs_results/reconstruction_error}
        \subcaption{The mean total angular error between the ground truth and 
                    normals constructed using a partially corrupted training 
                    set.}
\label{fig:reconstruction-error}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{statistical_normals/images/gsfs_results/Q}
        \subcaption{The value of Q for F001-Disgust in the 
                    BU4D-FE~\citet{yin2008high} data-set. The ideal line 
                    marks an upper bound for Q.}
        \label{fig:Q}
    \end{subfigure}
    \caption{Quantitative results for corrupted training sets.}
\label{fig:results-quant}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reconstruction Robustness}\label{subsec:Q}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We considered a set of $108$ aligned 3D face scans from the BU-4DFE data-set, 
specifically for subject F001 with the emotion `Disgust'. These scans capture 
the face of F001 whilst displaying a posed example of the emotion where she 
transitions from neutral, to apex and back to neutral. We create two principal 
subspaces from this set of scans. In the first, which we call 
$\bb{U}_{noise-free}$, we simply perform KPCA on the scans for each of 
the considered kernel functions. In the second, which we call 
$\bb{U}_{noisy}$, we artificially occlude 20\% of the scan with a 
randomly generated patch of normals. We occlude a total of 20\% of the images 
in the set before creating the noisy principal subspace. The performance 
measure we use to evaluate each kernel is independent of the feature-space, 
instead computing the total similarity between the principal components of 
$\bb{U}_{noise-free}$ and $\boldsymbol{U}_{noisy}$. Formally, the 
performance measure is defined as 
$Q = \sum_{i=1}^k \sum_{j=1}^k \cos(\alpha_{ij})$ where $\alpha_{ij}$ is the 
angle between each of the $k$ eigenvectors defined by
 $\bb{U}_{noise-free}$ and $\bb{U}_{noisy}$. 

The ideal value of $Q$ would be $k$, the number of coincident spaces, and is 
shown in \cref{fig:Q} as the black diamond-marked line. \cref{fig:Q} 
shows the mean value over 10 different sets of randomly placed normals for
F001-Disgust. In \cref{fig:Q} we can clearly see that AEP and SPHERICAL 
are the most robust to the noisy subspace.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reconstruction Evaluation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We used the same experimental setup as in \cref{subsec:Q} to produce 
$\bb{U}_{noisy}$ for each kernel. For every corrupted image in the 
training set we then projected it into the appropriate feature-space and 
reconstructed it with an increasing number of principal components from
 $\bb{U}_{noisy}$:
%%%%%%%%%%%%%%%%%%%%
\begin{equation}\label{eq:xtilde}
    \tilde{\bb{X}} = \phi^{-1} \left( \bb{U}_{noisy} \; {\bb{U}_{noisy}}^T \phi(\bb{X}) \right)
\end{equation}
%%%%%%%%%%%%%%%%%%%%
where $\phi$ and $\phi^{-1}$ are different for each method, as defined in 
\cref{subsec:singl_img_ca}. After reconstruction we project the 
feature vector back in to the input space of surface normals and re-normalised 
each normal. Finally, our evaluation metric was defined as the total angular
 error between the reconstructed and the ground truth normals.

The mean value of the total angular error for the first 10 principal 
components is given in \cref{fig:reconstruction-error}. Here we can 
see that SPHERICAL outperforms the other techniques by a large margin.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Shape-from-shading}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Images from the Photoface Database~\cite{zafeiriou2013photoface} were used to provide a 
ground truth model. We used the photometric stereo algorithm presented by 
\citet{barsky2003foursource} in order to reconstruct a set of normals. 
We consider the normals computed by photometric stereo as ground truth due to 
their relative accuracy over SFS\@.

Seven people from the data-set were chosen at random. The four images of each 
person were manually aligned and photometric stereo was performed to produce a
set of ground truth normals per subject. Then, one of the images was chosen 
and the GSFS framework described by \citet{smith2006recovering,smith2008facial}
was performed to reconstruct normals. The set of priors used to guide the GSFS 
was generated according to the KPCA framework described 
\cref{subsec:singl_img_ca} and the training set used was provided by 
building a model from the FRGC v2 dataset~\cite{phillips2005overview}.

The model was built from the Spring 2003 subset of the FRGC database after 
applying some simple pre-processing in the form of applying a $5 \times 5$ median 
filter. Each image in the FRGC 
database was manually annotated with 68 points, as were the images from the 
Photoface database. We performed a thin-plate spline warp to each depth image 
of the FRGC database into the reference space defined 
by the Photoface image landmarks and then computed the normals.
Due to the different reference spaces, a 
separate set of warped normals was built for each input image. Statistical 
models were then created from the warped normals according to the kernels 
described in \cref{subsec:singl_img_ca}.

To produce \cref{fig:sfs-results} we applied the procedure described in 
\cref{alg:gsfs} with each of the kernels, AEP, PGA, IP and SPHERICAL 
in turn. Once a set of best-fit normals was recovered from GSFS, we applied 
the integration method of \citet{frankot1988method}. 
Therefore, \cref{fig:sfs-results} shows the surfaces reconstructed 
after integration. \cref{fig:sfs-angle} shows the mean angular error 
per pixel. Here we see that SPHERICAL consistently outperforms the other 
kernels for angular error accuracy. SPHERICAL also performs well in terms of 
the mean height error between the photometric stereo reconstruction and the 
GSFS result as shown in \cref{fig:sfs-height}. \cref{fig:sfs-results} 
shows that the GSFS produces realistic results within this setting for all kernels.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}
    \centering
    \sfsimgsalltop{bej} \\
    \sfsimgsall{bln} \\
    \sfsimgsall{fav} \\
    \sfsimgsall{mut} \\
    \sfsimgsall{pet} \\
    \sfsimgsall{rob} \\
    \sfsimgsall{srb}
    \caption{Each row represents a subject. From top to bottom the subject 
             identifiers are `bej', `bln', `fav', `mut', `pet', `rob', `srb'.
             GT denotes ``Ground Truth'' and SPHER denotes the SPHERICAL 
             kernel.}
\label{fig:sfs-results}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Comparison to other SFS techniques}\label{subsec:sfs-compare}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Barron and Malik provide a state-of-the-art SFS technique in 
\cite{barron2015shape} which they call shape, illumination and 
reflectance from shading (SIRFS). We attempted to reconstruct the same input 
images given in the first column of \cref{fig:sfs-results} using the 
default parameters provided by the authors. An example of the output produced 
by the SIRFS algorithm is given in the final column of \cref{fig:sfs-results}. 
As we can see, the lack of prior knowledge produces a result that is clearly 
less accurate than the proposed statistical models of normals.

\citet{kemelmacher2011facereconstruction} propose a methodology to recover
facial shape from single images using a single template shape. Unfortunately, we
were unable to reproduce their results. However, \cref{fig:celebrities} shows
that when running GSFS on a subset of the same images of celebrities reported
in~\citet{kemelmacher2011facereconstruction}, we can achieve comparable results.
For example, in \cref{fig:celebrities} we can see that GSFS is also
capable of recovering the wrinkles from an input image. The results in
\cref{fig:celebrities} follow a similar methodology to the Photoface database
where the light direction is estimated as
in~\citet{kemelmacher2011facereconstruction} and the kernel used is SPHERICAL\@.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
    \centering
    \begin{subfigure}{0.23\textwidth}
        \centering
        \includegraphics[width=\textwidth]{statistical_normals/images/gsfs_results/celebrities/samuel_beckett.png}
\label{fig:samuel-beckett-input}
    \end{subfigure}
    \begin{subfigure}{0.23\textwidth}
        \centering
        \includegraphics[width=\textwidth]{statistical_normals/images/gsfs_results/celebrities/samuel_beckett_spherical.png}
\label{fig:samuel-beckett-no-texture}
    \end{subfigure}
    \begin{subfigure}{0.23\textwidth}
        \centering
        \includegraphics[width=\textwidth]{statistical_normals/images/gsfs_results/celebrities/samuel_beckett_spherical_texture.png}
    \end{subfigure}
    \begin{subfigure}{0.23\textwidth}
        \centering
        \includegraphics[width=\textwidth]{statistical_normals/images/gsfs_results/celebrities/samuel_beckett_spherical_wrinkles.png}
    \end{subfigure}
    \\
    \begin{subfigure}{0.23\textwidth}
        \centering
        \includegraphics[width=\textwidth]{statistical_normals/images/gsfs_results/celebrities/tom_hanks.png}
\label{fig:tom-hanks-input}
    \end{subfigure}
    \begin{subfigure}{0.23\textwidth}
        \centering
        \includegraphics[width=\textwidth]{statistical_normals/images/gsfs_results/celebrities/tom_hanks_spherical.png}
\label{fig:tom-hanks-no-texture}
    \end{subfigure}
    \begin{subfigure}{0.23\textwidth}
        \centering
        \includegraphics[width=\textwidth]{statistical_normals/images/gsfs_results/celebrities/tom_cruise_208.png}
\label{fig:tom-cruise-input}
    \end{subfigure}
    \begin{subfigure}{0.23\textwidth}
        \centering
        \includegraphics[width=\textwidth]{statistical_normals/images/gsfs_results/celebrities/tom_cruise_spherical.png}
\label{fig:tom-cruise-no-texture}
    \end{subfigure}
    \caption{The result of the GSFS algorithm on images of celebrities taken
             from~\cite{kemelmacher2011facereconstruction} using the SPHERICAL 
             kernel.}
\label{fig:celebrities}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
